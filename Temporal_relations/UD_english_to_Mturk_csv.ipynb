{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from predpatt import load_conllu\n",
    "from predpatt import PredPatt\n",
    "import csv\n",
    "\n",
    "ud_train  =  \"/Users/sidvash/facts_lab/veridicality_sid/UD_English/en-ud-train.conllu\"\n",
    "ud_dev  =  \"/Users/sidvash/facts_lab/veridicality_sid/UD_English/en-ud-dev.conllu\"\n",
    "ud_test  =  \"/Users/sidvash/facts_lab/veridicality_sid/UD_English/en-ud-test.conllu\"\n",
    "\n",
    "it_happnd = \"it-happened_eng_ud1.2_07092017.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract Sentence IDS of event-happening sentences\n",
    "data = pd.read_csv(it_happnd , sep='\\t')\n",
    "\n",
    "#Select only sentences which did happen\n",
    "happnd = data[data.Happened == \"true\"]\n",
    "\n",
    "#Exclude sentences with low confidence\n",
    "happnd = happnd[~happnd.Confidence.isin(['0', '1'])]\n",
    "\n",
    "#Create a set of IDs to filter later\n",
    "happen_set = set(list(happnd['Sentence.ID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_list(ud_data_path, happen_set):\n",
    "    '''\n",
    "    Extract a list of JSON objects from the ud data\n",
    "    \n",
    "    Input: \n",
    "    1. ud data path ending in .conll\n",
    "    2. happen_set: a set of sentence_id where the event did happen\n",
    "    \n",
    "    '''\n",
    "    fname = ud_data_path.split(\"/\")[-1]\n",
    "    \n",
    "    with open(ud_data_path) as infile:\n",
    "        data = infile.read()\n",
    "        parsed = [(PredPatt(ud_parse), sent_id) for sent_id, ud_parse in load_conllu(data)]\n",
    "        \n",
    "    \n",
    "    id = 1\n",
    "    global_list = []\n",
    "    local_list = []\n",
    "\n",
    "    for parse_sen in parsed:\n",
    "        \n",
    "        for predicate in parse_sen[0].instances:\n",
    "            raw_sentence = [token.text for token in parse_sen[0].tokens]\n",
    "            pred_token = predicate.root.position\n",
    "            pred = predicate.root.text\n",
    "            #print(raw_sentence)\n",
    "            #print(pred_token)\n",
    "            #print(pred)\n",
    "\n",
    "            token_dict = {}\n",
    "            pred_sentence = raw_sentence.copy()\n",
    "            pred_sentence.insert(pred_token, '<span class=\\\"predicate\\\">')\n",
    "            pred_sentence.insert(pred_token + 2, '</span>')\n",
    "            sentid_num = parse_sen[1].split(\"_\")[-1]\n",
    "\n",
    "            token_dict['pred_token'] = str(pred_token)\n",
    "            token_dict['sentence'] = \" \".join(pred_sentence)\n",
    "            token_dict['pred'] = pred\n",
    "            token_dict['sentence_id'] = fname + \" \" + sentid_num\n",
    "            token_dict['id'] = id\n",
    "\n",
    "            if token_dict['sentence_id'] not in happen_set:\n",
    "                break\n",
    "\n",
    "            id += 1\n",
    "\n",
    "            if id == 11:\n",
    "                id = 1 \n",
    "\n",
    "            if len(local_list) == 10:\n",
    "                global_list.append(local_list)\n",
    "                local_list = []\n",
    "                local_list.append(json.dumps(token_dict))\n",
    "            else:\n",
    "                local_list.append(json.dumps(token_dict))\n",
    "                    \n",
    "    return global_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_string(s):\n",
    "    '''\n",
    "    Make some changes to the input string to make it Turk readable\n",
    "    '''\n",
    "\n",
    "    #replace all single quotes by double quotes : except at the start/end of the list\n",
    "    s = re.sub(r'([^\\]])\\\"', r'\\1\"\"', s)\n",
    "    \n",
    "    #replace single quotes\n",
    "    s = re.sub(r\"\\'\\{\", r\"{\", s)  \n",
    "    s = re.sub(r\"\\}\\'\", r\"}\", s)\n",
    "    \n",
    "    #replace two backslash to three\n",
    "    s = re.sub(r\"\\\\\\\\\", r\"\\\\\\\\\\\\\", s)\n",
    "    \n",
    "    #remove spaces before and after span\n",
    "    s = re.sub(r\"> \", r\">\", s)\n",
    "    s = re.sub(r\" <\", r\"<\", s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl_list = extract_list(ud_dev, happen_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a csv file for MTurk:\n",
    "with open('test.csv', 'w+') as file_handler:\n",
    "    file_handler.write(\"var_arrays\\n\")\n",
    "    for item in gl_list:\n",
    "        local_str = \"\\\"\" + str(item) + \"\\\"\\n\"\n",
    "        file_handler.write(local_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read csv file created above and store into list\n",
    "file_temp = open('test.csv', 'r')\n",
    "lines = file_temp.readlines()\n",
    "file_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a csv file for MTurk with replacements:\n",
    "with open('test_replace.csv', 'w+') as file_handler:\n",
    "    for item in lines:\n",
    "        file_handler.write(replace_string(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Temporary command to replace lines manually that throw error on Turk:\n",
    "\n",
    "#####  run from terminal:\n",
    "#sed '5d;6d;8d;9d;14d;15d;28d;60d;93d;127d;128d;130d;131d;182d;210d' < test_replace.csv > test_replace_v2.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
