{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from scipy.stats import pearsonr as pearson\n",
    "from scipy.stats import spearmanr as spearman\n",
    "from math import isnan\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"pred_train.csv\"\n",
    "raw_train_file = pd.read_csv(train_file)\n",
    "raw_train_file.columns = [c.replace('.', '_') for c in raw_train_file.columns]\n",
    "\n",
    "devte_file = \"pred_devtest.csv\"\n",
    "raw_devte_file = pd.read_csv(devte_file)\n",
    "raw_devte_file.columns = [c.replace('.', '_') for c in raw_devte_file.columns]\n",
    "print(len(raw_train_file), len(raw_devte_file))\n",
    "raw_data_file = raw_train_file.append(raw_devte_file, ignore_index=True)\n",
    "\n",
    "happ_file = \"it-happened_eng_ud1.2_07092017.tsv\"\n",
    "happ = pd.read_csv(happ_file, sep=\"\\t\")\n",
    "\n",
    "tmp_file = 'check_data.csv'\n",
    "tmp = pd.read_csv(tmp_file, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataframe(data):\n",
    "    '''\n",
    "    Input: Pandas csv dataframe obtained from MTurk\n",
    "    \n",
    "    Output: Pandas dataframe levelled by (User x Sentenced_ID)\n",
    "    '''\n",
    "    data[\"dicts\"] = data[\"Input_var_arrays\"].map(lambda x: json.loads(x))\n",
    "    global_list = []\n",
    "    \n",
    "    for row in data.itertuples():\n",
    "        for idx, local_dict in enumerate(row.dicts):\n",
    "            temp_dict = local_dict.copy()\n",
    "            var_dyn = \"Answer_pred_dyn\" + str(idx + 1)\n",
    "            var_dyn_c = \"Answer_dyn_conf\" + str(idx + 1)\n",
    "            var_part = \"Answer_pred_part\" + str(idx + 1)\n",
    "            var_part_c = \"Answer_part_conf\" + str(idx + 1)\n",
    "            var_hyp = \"Answer_pred_hyp\" + str(idx + 1)\n",
    "            var_hyp_c = \"Answer_hyp_conf\" + str(idx + 1)\n",
    "            temp_dict['part'] = getattr(row, var_part)\n",
    "            temp_dict['part_conf'] = getattr(row, var_part_c)\n",
    "            temp_dict['dyn'] = getattr(row, var_dyn)\n",
    "            temp_dict['dyn_conf'] = getattr(row, var_dyn_c)\n",
    "            temp_dict['hyp'] = getattr(row, var_hyp)\n",
    "            temp_dict['hyp_conf'] = getattr(row, var_hyp_c)\n",
    "            temp_dict['worker_id'] = row.WorkerId\n",
    "            temp_dict['hit_id'] = row.HITId\n",
    "            temp_dict['status'] = row.AssignmentStatus\n",
    "            global_list.append(temp_dict)\n",
    "    \n",
    "    return pd.DataFrame(global_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = extract_dataframe(raw_data_file)\n",
    "raw_data = raw_data[raw_data['status']!='Rejected']\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "raw_data['sent_pred'] = raw_data['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "                           raw_data['pred_token'].map(lambda x: str(x))\n",
    "raw_data['pred_pos'] = None\n",
    "tmp['sent_pred'] = tmp['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "                           tmp['pred_token'].map(lambda x: str(x))\n",
    "\n",
    "for i, _ in raw_data.iterrows():\n",
    "    raw_data.at[i, 'pred_pos'] = tmp.loc[tmp['sent_pred'] == raw_data.at[i, 'sent_pred'], 'pos'].values[0]\n",
    "    \n",
    "raw_data['sent_predpos'] = raw_data['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "                           raw_data['pred_pos'].map(lambda x: str(x))\n",
    "happ['Pred.Token'] -= 1\n",
    "happ['sent_pred'] = happ['Sentence.ID'].map(lambda x : x) + \"_\" +\\\n",
    "                           happ['Pred.Token'].map(lambda x: str(x))\n",
    "# Rearrange the columns\n",
    "cols = ['hit_id', 'worker_id','sent_pred', 'predicate', 'pred_pos','sent_predpos', 'sent_id','pred_token','part','part_conf',\n",
    "        'dyn','dyn_conf','hyp','hyp_conf']\n",
    "data = raw_data[cols]\n",
    "\n",
    "\n",
    "happ = happ[happ['Happened'] != 'na']\n",
    "\n",
    "happ['Happened'] = happ['Happened'].map({'true': 1, 'false': 0})\n",
    "data['hyp'] = data['hyp'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "x2 = []\n",
    "print(len(data))\n",
    "comm =  set(list(data['sent_predpos'].values)).intersection(set(list(happ['sent_pred'].values)))\n",
    "print(len(list(comm)))\n",
    "for m in comm:\n",
    "    x1.append(data[data['sent_predpos'] == m]['hyp'].values[0])\n",
    "    x2.append(happ[happ['sent_pred'] == m]['Happened'].values[0])\n",
    "print(pearson(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sqrt\n",
    "# cm = {'tp':0, 'tn':0, 'fp':0, 'fn':0}\n",
    "# for i in range(len(x1)):\n",
    "#     if x1[i] == x2[i]:\n",
    "#         if x1[i] == 1:\n",
    "#             cm['tp'] += 1\n",
    "#         else:\n",
    "#             cm['tn'] += 1\n",
    "#     else:\n",
    "#         if x1[i] == 1:\n",
    "#             cm['fp'] += 1\n",
    "#         else:\n",
    "#             cm['fn'] += 1\n",
    "# print(cm)\n",
    "# matthew = (cm['tp'] * cm['tn'] - cm['fp'] * cm['fn']) / sqrt((cm['tp'] + cm['fp'])*(cm['tp'] + cm['fn'])*(cm['tn'] + cm['fp'])*(cm['tn'] + cm['fn']))\n",
    "# print(matthew)\n",
    "# conf_mat = [[cm['tn'], cm['fp']], [cm['fn'], cm['tp']]]\n",
    "# df_cm = pd.DataFrame(conf_mat, index=['False', 'True'], columns=['False', 'True'])\n",
    "# plt.figure(figsize = (10,7))\n",
    "# sns.heatmap(df_cm, annot=True)\n",
    "# Counter(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long form dataset\n",
    "long_cols = ['Split', 'Annotator.ID','Sentence.ID','Pred.Root.Token', 'Pred.Tokens','Predicate',\n",
    "             'Is.Particular', 'Part.Confidence', 'Is.Dynamic','Dyn.Confidence',\n",
    "             'Is.Hypothetical','Hyp.Confidence']\n",
    "\n",
    "long_data = data.copy()\n",
    "long_data = long_data.rename(columns={'worker_id':'Annotator.ID', 'sent_id':'Sentence.ID',\n",
    "                                      'pred_pos':'Pred.Root.Token', 'pred_token':'Pred.Tokens',\n",
    "                                      'predicate':'Predicate', 'part':'Is.Particular', \n",
    "                                      'part_conf':'Part.Confidence', 'dyn':'Is.Dynamic', \n",
    "                                      'dyn_conf':'Dyn.Confidence', 'hyp':'Is.Hypothetical', \n",
    "                                      'hyp_conf':'Hyp.Confidence'})\n",
    "\n",
    "long_data['Split'] = long_data['Sentence.ID'].str[6:11]\n",
    "long_data['Split'] = long_data['Split'].map(lambda x: x.rstrip('.c'))\n",
    "\n",
    "ann_hash = {}\n",
    "annid = 0\n",
    "for ann in set(long_data['Annotator.ID'].values):\n",
    "    annid += 1\n",
    "    ann_hash[ann] = annid\n",
    "long_data['Annotator.ID'] = long_data['Annotator.ID'].map(ann_hash)\n",
    "long_data = long_data[long_cols]\n",
    "long_data['Is.Hypothetical'] = long_data['Is.Hypothetical'].map({1: True, 0: False})\n",
    "long_data.to_csv('long_data.tsv', sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
