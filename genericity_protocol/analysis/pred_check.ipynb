{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr as pearson\n",
    "from scipy.stats import spearmanr as spearman\n",
    "from math import isnan\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data.csv\"\n",
    "raw_data_file = pd.read_csv(data_file)\n",
    "raw_data_file.columns = [c.replace('.', '_') for c in raw_data_file.columns]\n",
    "\n",
    "happ_file = \"it-happened_eng_ud1.2_07092017.tsv\"\n",
    "happ = pd.read_csv(happ_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataframe(data):\n",
    "    '''\n",
    "    Input: Pandas csv dataframe obtained from MTurk\n",
    "    \n",
    "    Output: Pandas dataframe levelled by (User x Sentenced_ID)\n",
    "    '''\n",
    "    data[\"dicts\"] = data[\"Input_var_arrays\"].map(lambda x: json.loads(x))\n",
    "    global_list = []\n",
    "    \n",
    "    for row in data.itertuples():\n",
    "        for idx, local_dict in enumerate(row.dicts):\n",
    "            temp_dict = local_dict.copy()\n",
    "            var_dyn = \"Answer_pred_dyn\" + str(idx + 1)\n",
    "            var_dyn_c = \"Answer_dyn_conf\" + str(idx + 1)\n",
    "            var_part = \"Answer_pred_part\" + str(idx + 1)\n",
    "            var_part_c = \"Answer_part_conf\" + str(idx + 1)\n",
    "            var_hyp = \"Answer_pred_hyp\" + str(idx + 1)\n",
    "            var_hyp_c = \"Answer_hyp_conf\" + str(idx + 1)\n",
    "            temp_dict['part'] = getattr(row, var_part)\n",
    "            temp_dict['part_conf'] = getattr(row, var_part_c)\n",
    "            temp_dict['dyn'] = getattr(row, var_dyn)\n",
    "            temp_dict['dyn_conf'] = getattr(row, var_dyn_c)\n",
    "            temp_dict['hyp'] = getattr(row, var_hyp)\n",
    "            temp_dict['hyp_conf'] = getattr(row, var_hyp_c)\n",
    "            temp_dict['worker_id'] = row.WorkerId\n",
    "            temp_dict['hit_id'] = row.HITId\n",
    "            temp_dict['status'] = row.AssignmentStatus\n",
    "            global_list.append(temp_dict)\n",
    "    \n",
    "    return pd.DataFrame(global_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = extract_dataframe(raw_data_file)\n",
    "raw_data = raw_data[raw_data['status']!='Rejected']\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "raw_data['sent_pred'] = raw_data['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "                           raw_data['pred_token'].map(lambda x: str(x))\n",
    "# print(raw_data.head())\n",
    "# raw_data['pred_pos'] = None\n",
    "# tmp['sent_pred'] = tmp['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "#                            tmp['pred_token'].map(lambda x: str(x))\n",
    "\n",
    "# for i, _ in raw_data.iterrows():\n",
    "#     raw_data.at[i, 'pred_pos'] = tmp.loc[tmp['sent_pred'] == raw_data.at[i, 'sent_pred'], 'pos'].values[0]\n",
    "    \n",
    "# raw_data['sent_predpos'] = raw_data['sent_id'].map(lambda x : x) + \"_\" +\\\n",
    "#                            raw_data['pred_pos'].map(lambda x: str(x))\n",
    "# happ['Pred.Token'] -= 1\n",
    "# happ['sent_pred'] = happ['Sentence.ID'].map(lambda x : x) + \"_\" +\\\n",
    "#                            happ['Pred.Token'].map(lambda x: str(x))\n",
    "# # Rearrange the columns\n",
    "cols = ['hit_id', 'worker_id','sent_pred', 'predicate', 'pred_root_pos', 'sent_id','pred_token','part','part_conf',\n",
    "        'dyn','dyn_conf','hyp','hyp_conf']\n",
    "data = raw_data[cols]\n",
    "\n",
    "\n",
    "# happ = happ[happ['Happened'] != 'na']\n",
    "\n",
    "# happ['Happened'] = happ['Happened'].map({'true': 1, 'false': 0})\n",
    "# data['hyp'] = data['hyp'].map({True: 1, False: 0})\n",
    "\n",
    "# print(data.head())\n",
    "# # print(happ.head())\n",
    "\n",
    "# Here you can check each individual annotator and see if they are following the norm\n",
    "x=Counter(list(data['worker_id'].values))\n",
    "print(x.most_common()[:15])\n",
    "print(data.shape)\n",
    "ann_data = data[data['worker_id']=='A215S35FQFQYJ1']\n",
    "x_data = data[data['worker_id'] != 'A3CJWEYFZ8W42Y']\n",
    "x_data = x_data[x_data['worker_id']!= 'A215S35FQFQYJ1']\n",
    "print(ann_data.shape)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare one annotator to rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=6, figsize=(15, 15))\n",
    "sns.countplot(x='part', data=x_data, ax=axs[0][0])\n",
    "sns.countplot(x='part', data=ann_data, ax=axs[0][1])\n",
    "sns.countplot(x='dyn', data=x_data, ax=axs[1][0])\n",
    "sns.countplot(x='dyn', data=ann_data, ax=axs[1][1])\n",
    "sns.countplot(x='hyp', data=x_data, ax=axs[2][0])\n",
    "sns.countplot(x='hyp', data=ann_data, ax=axs[2][1])\n",
    "\n",
    "sns.countplot(x='part_conf', data=x_data, ax=axs[3][0])\n",
    "sns.countplot(x='part_conf', data=ann_data, ax=axs[3][1])\n",
    "sns.countplot(x='dyn_conf', data=x_data, ax=axs[4][0])\n",
    "sns.countplot(x='dyn_conf', data=ann_data, ax=axs[4][1])\n",
    "sns.countplot(x='hyp_conf', data=x_data, ax=axs[5][0])\n",
    "sns.countplot(x='hyp_conf', data=ann_data, ax=axs[5][1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation between it happened and hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(happ.head())\n",
    "# x1 = []\n",
    "# x2 = []\n",
    "# print(len(data))\n",
    "# comm =  set(list(data['sent_predpos'].values)).intersection(set(list(happ['sent_pred'].values)))\n",
    "# print(len(list(comm)))\n",
    "# for m in comm:\n",
    "#     x1.append(data[data['sent_predpos'] == m]['hyp'].values[0])\n",
    "#     x2.append(happ[happ['sent_pred'] == m]['Happened'].values[0])\n",
    "# print(pearson(x1, x2))\n",
    "\n",
    "from math import sqrt\n",
    "cm = {'tp':0, 'tn':0, 'fp':0, 'fn':0}\n",
    "for i in range(len(x1)):\n",
    "    if x1[i] == x2[i]:\n",
    "        if x1[i] == 1:\n",
    "            cm['tp'] += 1\n",
    "        else:\n",
    "            cm['tn'] += 1\n",
    "    else:\n",
    "        if x1[i] == 1:\n",
    "            cm['fp'] += 1\n",
    "        else:\n",
    "            cm['fn'] += 1\n",
    "print(cm)\n",
    "matthew = (cm['tp'] * cm['tn'] - cm['fp'] * cm['fn']) / sqrt((cm['tp'] + cm['fp'])*(cm['tp'] + cm['fn'])*(cm['tn'] + cm['fp'])*(cm['tn'] + cm['fn']))\n",
    "print(matthew)\n",
    "conf_mat = [[cm['tn'], cm['fp']], [cm['fn'], cm['tp']]]\n",
    "df_cm = pd.DataFrame(conf_mat, index=['False', 'True'], columns=['False', 'True'])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "Counter(x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
